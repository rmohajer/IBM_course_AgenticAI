{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21fa2e13-567d-4509-9023-c99fb230f31f",
   "metadata": {},
   "source": [
    "# Lesson 2 : LangGraph Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import httpx\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "model_id = \"openai/gpt-oss-120b\" # \tqwen/qwen3-32b  openai/gpt-oss-120b llama-3.1-8b-instant\n",
    "    \n",
    "llm = ChatGroq(model=model_id,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n",
      "tavily_search_results_json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0z/6z_9lrtd6j3_gnlsyv9rb5b00000gn/T/ipykernel_39419/144666821.py:1: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tool = TavilySearchResults(max_results=4) #increased number of results\n"
     ]
    }
   ],
   "source": [
    "tool = TavilySearchResults(max_results=4) #increased number of results\n",
    "print(type(tool))\n",
    "print(tool.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e196c186-af55-4f2d-b569-b7d63a859304",
   "metadata": {},
   "source": [
    "> If you are not familiar with python typing annotation, you can refer to the [python documents](https://docs.python.org/3/library/typing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c7ba73-e603-453b-b06f-5db92c567b19",
   "metadata": {},
   "source": [
    "> Note: in `take_action` below, some logic was added to cover the case that the LLM returned a non-existent tool name. Even with function calling, LLMs can still occasionally hallucinate. Note that all that is done is instructing the LLM to try again! An advantage of an agentic organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 727
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    def __init__(self, model, tools, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\",\n",
    "            self.exists_action,\n",
    "            {True: \"action\", False: END}\n",
    "        )\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile()\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            if not t['name'] in self.tools:      # check for bad tool name from LLM\n",
    "                print(\"\\n ....bad tool name....\")\n",
    "                result = \"bad tool name, retry\"  # instruct LLM to retry if bad\n",
    "            else:\n",
    "                result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "abot = Agent(llm, [tool], system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather San Francisco'}, 'id': 'fc_079e1d51-c423-48eb-9e44-d15860f6753a', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco current temperature November 1 2025'}, 'id': 'fc_115868ab-20ee-4385-b042-4e2269eb29e5', 'type': 'tool_call'}\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89a06a8c-fcd4-4ca6-98f0-36c5809813e6",
   "metadata": {
    "height": 30,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Current weather in San Francisco (as of Saturday Nov 1 2025)**  \n",
      "\n",
      "| Item | Details |\n",
      "|------|---------|\n",
      "| **Condition** | Mostly sunny with low‑level clouds and fog early in the morning; the fog clears as the day progresses. |\n",
      "| **Temperature** | High around **67 °F (19 °C)**. Overnight low around **55 °F (13 °C)**. |\n",
      "| **Wind** | Light and variable, generally from the west‑northwest at 5‑15 mph. |\n",
      "| **Humidity** | Mid‑50 % to low‑60 % (typical for a foggy morning). |\n",
      "| **Visibility** | Reduced in the early morning due to fog, improving to clear/mostly clear later in the day. |\n",
      "| **Precipitation** | None reported for today; only a few scattered clouds expected tonight. |\n",
      "| **Short‑term forecast** | <br>• **Tonight:** Mainly clear early, then patchy low clouds and fog. <br>• **Sunday (Nov 2):** Fog turning to sun, partly cloudy. <br>• **Monday (Nov 3):** Partly sunny, increasing cloudiness. |\n",
      "\n",
      "*Sources:* AccuWeather’s “Today” page for San Francisco (high 67 °F, low 55 °F, fog early) and Weather.com’s 10‑day outlook (high 68 °F, low 52 °F, light winds). Both services agree on a sunny‑to‑partly‑cloudy day with early fog.\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].model_dump()['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather San Francisco'}, 'id': 'fc_2ace4188-f835-4f3c-9758-94caf2455154', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco current weather'}, 'id': 'fc_4724090d-3bed-4651-a503-b213830d28c4', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco weather now'}, 'id': 'fc_8edfefda-2f1c-47d2-a75c-4d302c943bcb', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Los Angeles current weather'}, 'id': 'fc_7b7bdb24-95f1-494d-b707-0b978ac612bf', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco weather now temperature'}, 'id': 'fc_f9e8de5e-77a9-4ff8-94f2-2a18c9b881fc', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco current temperature weather.com'}, 'id': 'fc_789e7df4-fab8-430d-8ac3-97ee1bd98eff', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco current temperature 2025-11-01 weather.com'}, 'id': 'fc_1e379354-cff7-4370-b2e7-4449306bceb2', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Los Angeles weather now temperature weather.com'}, 'id': 'fc_173d8c4d-6fba-46e8-9bc1-67a4b1c6d949', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Los Angeles weather today November 1 2025'}, 'id': 'fc_3eb79d58-ed29-46f1-869b-3f447ec00d7f', 'type': 'tool_call'}\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF and LA?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Weather – Nov 1 2025 (today)**  \n",
      "\n",
      "| City | Current condition | Temperature (high / low) | Wind | Chance of rain |\n",
      "|------|-------------------|---------------------------|------|----------------|\n",
      "| **San Francisco (SF)** | Partly‑cloudy with occasional fog patches | **68 °F / 54 °F** (≈ 20 °C / 12 °C) | West 10‑15 mph (light) | 20‑30 % (scattered showers possible) |\n",
      "| **Los Angeles (LA)** | Sunny, clear skies | **75 °F / 59 °F** (≈ 24 °C / 15 °C) | Light / variable (≈ 5‑10 mph) | < 5 % (dry) |\n",
      "\n",
      "**What this means**\n",
      "\n",
      "* **San Francisco** – The day will be mild and mostly sunny, but the typical coastal fog may drift in during the morning, giving way to partly‑cloudy skies by mid‑day. Temperatures stay in the upper‑60 °F range, with a light west wind. There’s a modest chance of an isolated shower or drizzle, especially near the coast.\n",
      "\n",
      "* **Los Angeles** – Expect a classic Southern‑California November day: bright sunshine, warm daytime highs in the mid‑70 °F, and comfortable evenings in the upper‑50 °F. Winds are light and variable, and rain is unlikely.\n",
      "\n",
      "*Both cities are in the “good” part of the November climate pattern for California – dry, mild, and pleasant.*\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 183
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Missouri GDP 2023'}, 'id': 'fc_3c62a73c-5319-444b-ac1a-6f11eaa77e63', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Super Bowl 2024 winner Kansas City Chiefs'}, 'id': 'fc_6eec62ca-3564-4936-b201-dd4a116c08f6', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Missouri GDP 2024 real GDP $356.7 billion'}, 'id': 'fc_599ec43a-7a6c-40a6-9fe0-ce43442eef43', 'type': 'tool_call'}\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "# Note, the query was modified to produce more consistent results. \n",
    "# Results may vary per run and over time as search information and models change.\n",
    "\n",
    "query = \"Who won the super bowl in 2024? In what state is the winning team headquarters located? \\\n",
    "What is the GDP of that state? Answer each question.\" \n",
    "messages = [HumanMessage(content=query)]\n",
    "\n",
    "abot = Agent(llm, [tool], system=prompt)\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**1. Who won the Super Bowl in 2024?**  \n",
      "- The **Kansas City Chiefs** won Super Bowl LVIII (played on February 11 2024), defeating the San Francisco 49ers 25‑22 in overtime【2†L1-L8】.\n",
      "\n",
      "**2. In what state is the winning team’s headquarters located?**  \n",
      "- The Kansas City Chiefs are headquartered in **Kansas City, Missouri** (the franchise’s home city and state).\n",
      "\n",
      "**3. What is the GDP of that state?**  \n",
      "- According to USAFacts, **Missouri’s real Gross Domestic Product (GDP) in 2024 was $356.7 billion**【3†L1-L7】.  \n",
      "- (The U.S. Bureau of Economic Analysis also reports Missouri’s inflation‑adjusted GDP for 2024 at about **$353 billion**【3†L8-L12】.)\n",
      "\n",
      "**Answer Summary**\n",
      "\n",
      "| Question | Answer |\n",
      "|----------|--------|\n",
      "| Super Bowl 2024 winner | Kansas City Chiefs |\n",
      "| State of the team’s headquarters | Missouri |\n",
      "| Missouri’s 2024 GDP (real) | Approximately **$356.7 billion** (USAFacts) – roughly **$353 billion** (BEA) |\n",
      "\n",
      "Thus, the Kansas City Chiefs won the 2024 Super Bowl, they are based in Missouri, and Missouri’s GDP in 2024 was about $356 billion.\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d643182-2802-40fb-ba35-d4f893c5b976",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IBM_course_AgenticAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
