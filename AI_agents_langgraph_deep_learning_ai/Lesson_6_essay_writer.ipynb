{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911b3b37-3b29-4833-94f2-bfe47af00c83",
   "metadata": {},
   "source": [
    "# Lesson 6: Essay Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tavily import TavilyClient\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "model_id = \"llama-3.1-8b-instant\" # \tqwen/qwen3-32b  openai/gpt-oss-20b llama-3.1-8b-instant\n",
    "    \n",
    "llm = ChatGroq(model=model_id,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "# from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "memory = InMemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an essay. \\\n",
    "Write such an outline for the user provided topic. Give an outline of the essay along with any relevant notes \\\n",
    "or instructions for the sections.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 5-paragraph essays.\\\n",
    "Generate the best essay possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize all the information below as needed: \n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "714d1205-f8fc-4912-b148-2a45da99219c",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following essay. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "import os\n",
    "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "def plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT), \n",
    "        HumanMessage(content=state['task'])\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"plan\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "def research_plan_node(state: AgentState):\n",
    "    queries = llm.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98f303b1-a4d0-408c-8cc0-515ff980717f",
   "metadata": {
    "height": 285
   },
   "outputs": [],
   "source": [
    "def generation_node(state: AgentState):\n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\")\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=WRITER_PROMPT.format(content=content)\n",
    "        ),\n",
    "        user_message\n",
    "        ]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response.content, \n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf4dcb93-6298-4cfd-b3ce-61dfac7fb35f",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT), \n",
    "        HumanMessage(content=state['draft'])\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"critique\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "932883a4-c722-42bb-aec0-b4f41c5c81a4",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "def research_critique_node(state: AgentState):\n",
    "    queries = llm.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "        HumanMessage(content=state['critique'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff362f49-dcf1-4ea1-a86c-e516e9ab897d",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7e15a20-83d7-434c-8551-bce8dcc32be0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54ab2c74-f32e-490c-a85d-932d11444210",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x30bebeff0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a833d3ce-bd31-4319-811d-decff226b970",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x30bebeff0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.set_entry_point(\"planner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76e93cce-6eab-4c7c-ac64-e9993fdb30d6",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x30bebeff0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_conditional_edges(\n",
    "    \"generate\", \n",
    "    should_continue, \n",
    "    {END: END, \"reflect\": \"reflect\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd2d0990-a932-423f-9ff3-5cada58c5f32",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x30bebeff0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27cde654-64e2-48bc-80a9-0ed668ccb7dc",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98f3be1d-cc4c-41fa-9863-3e386e88e305",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'planner': {'plan': \"Here's a high-level outline for an essay on the differences between LangChain and LangSmith:\\n\\n**I. Introduction**\\n- Briefly introduce the topic of AI-powered language models and their applications\\n- Mention LangChain and LangSmith as two prominent tools in this space\\n- Thesis statement: While both LangChain and LangSmith are AI-powered language tools, they differ in their approach, functionality, and use cases.\\n\\n**II. Overview of LangChain**\\n- Define LangChain and its core features\\n- Explain how LangChain enables users to build custom AI applications using a modular architecture\\n- Highlight LangChain's strengths, such as its flexibility and scalability\\n- Relevant notes: LangChain is an open-source framework that allows users to create custom AI models and integrate them with various data sources.\\n\\n**III. Overview of LangSmith**\\n- Define LangSmith and its core features\\n- Explain how LangSmith uses a combination of natural language processing (NLP) and machine learning to generate human-like text\\n- Highlight LangSmith's strengths, such as its ability to generate coherent and engaging text\\n- Relevant notes: LangSmith is a commercial AI tool that offers a range of features, including text generation, summarization, and translation.\\n\\n**IV. Key differences between LangChain and LangSmith**\\n- Compare the two tools in terms of their architecture, functionality, and use cases\\n- Discuss how LangChain's modular architecture allows for greater flexibility and customization, while LangSmith's pre-built features make it easier to use for non-technical users\\n- Highlight the different industries and applications where each tool is best suited (e.g. LangChain for custom AI development, LangSmith for content creation and marketing)\\n\\n**V. Conclusion**\\n- Summarize the main differences between LangChain and LangSmith\\n- Reiterate the thesis statement and emphasize the importance of choosing the right tool for a specific use case\\n- Final thoughts: As AI technology continues to evolve, it's essential to understand the strengths and weaknesses of different tools like LangChain and LangSmith to make informed decisions about their use in various applications.\"}}\n",
      "{'research_plan': {'content': ['In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. | Key Features | Modular chains and sequences, prompt templates, agent framework, data connectors, wide model support, community integrations. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. | Key Features | Modular chains and sequences, prompt templates, agent framework, data connectors, wide model support, community integrations. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', 'In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. | Key Features | Modular chains and sequences, prompt templates, agent framework, data connectors, wide model support, community integrations. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.']}}\n",
      "{'generate': {'draft': \"Here's a 5-paragraph essay based on your outline:\\n\\nThe rapid advancement of artificial intelligence (AI) has led to the development of various tools and frameworks that enable users to build and manage AI-powered language models. Two prominent tools in this space are LangChain and LangSmith, each with its unique approach, functionality, and use cases. While both tools are designed to facilitate the creation and deployment of AI models, they differ significantly in their architecture, features, and applications. This essay aims to explore the differences between LangChain and LangSmith, highlighting their strengths and weaknesses, and providing insights into their suitability for various use cases.\\n\\nLangChain is an open-source framework that enables users to build custom AI applications using a modular architecture. This flexibility allows developers to create tailored solutions that meet specific requirements, making LangChain an ideal choice for complex AI development projects. LangChain's strengths lie in its scalability, flexibility, and customizability, making it a popular choice among developers who require a high degree of control over their AI models. In contrast, LangSmith is a commercial AI tool that offers a range of pre-built features, including text generation, summarization, and translation. While LangSmith is easier to use for non-technical users, its limitations in terms of customization and flexibility make it less suitable for complex AI development projects.\\n\\nOne of the key differences between LangChain and LangSmith is their approach to AI model development. LangChain takes a modular approach, allowing users to build custom AI models using a combination of pre-built components and APIs. This approach enables developers to create highly customized solutions that meet specific requirements. In contrast, LangSmith uses a combination of natural language processing (NLP) and machine learning to generate human-like text. While LangSmith's pre-built features make it easier to use for content creation and marketing applications, its limitations in terms of customization and flexibility make it less suitable for complex AI development projects.\\n\\nThe different industries and applications where each tool is best suited are another key difference between LangChain and LangSmith. LangChain is ideal for custom AI development projects, such as building chatbots, virtual assistants, and other complex AI applications. LangSmith, on the other hand, is better suited for content creation and marketing applications, such as generating product descriptions, social media posts, and other types of text-based content. While both tools can be used for a wide range of applications, their strengths and weaknesses make them more suitable for specific use cases.\\n\\nIn conclusion, LangChain and LangSmith are two distinct tools that cater to different needs and use cases in the AI-powered language model space. While LangChain offers flexibility, scalability, and customizability, LangSmith provides ease of use, pre-built features, and a range of applications. Understanding the strengths and weaknesses of each tool is essential for making informed decisions about their use in various applications. As AI technology continues to evolve, it's crucial to choose the right tool for a specific use case, ensuring that the chosen tool meets the requirements and delivers the desired outcomes.\", 'revision_number': 2}}\n",
      "{'reflect': {'critique': \"**Overall Assessment:**\\nYour essay provides a clear and concise comparison of LangChain and LangSmith, highlighting their strengths and weaknesses, and discussing their suitability for various use cases. However, there are areas for improvement in terms of depth, length, and style.\\n\\n**Strengths:**\\n\\n1. Clear structure: Your essay follows a logical structure, starting with an introduction, followed by a comparison of the two tools, and concluding with a summary of their differences.\\n2. Good use of examples: You provide specific examples of the tools' strengths and weaknesses, making it easier for readers to understand their applications.\\n3. Concise writing: Your writing is clear and concise, making it easy to follow and understand.\\n\\n**Weaknesses and Recommendations:**\\n\\n1. **Length:** Your essay is a bit short, considering the complexity of the topic. I recommend expanding it to at least 7-8 paragraphs, including more detailed comparisons and examples.\\n2. **Depth:** While you provide a good overview of the tools, you could delve deeper into their technical aspects, such as their architecture, algorithms, and APIs. This would make your essay more informative and valuable for readers.\\n3. **Style:** Your writing is clear, but it's a bit formal and lacks a personal touch. Consider adding more engaging language and anecdotes to make your essay more enjoyable to read.\\n4. **Transitions:** Your paragraphs could flow better with more transitional phrases and sentences. This would help to connect your ideas and make your essay more cohesive.\\n5. **Conclusion:** While your conclusion is a good summary of the main points, it's a bit too brief. I recommend expanding it to include more insights and recommendations for readers.\\n\\n**Specific Recommendations:**\\n\\n1. **Paragraph 1:** Consider adding more context about the importance of AI-powered language models and the role of LangChain and LangSmith in this space.\\n2. **Paragraph 2:** Provide more details about LangChain's modular architecture and how it enables developers to create custom AI applications.\\n3. **Paragraph 3:** Delve deeper into LangSmith's pre-built features and how they make it easier to use for content creation and marketing applications.\\n4. **Paragraph 4:** Provide more examples of industries and applications where each tool is best suited, and discuss the implications of choosing one tool over the other.\\n5. **Conclusion:** Consider adding more insights about the future of AI-powered language models and how LangChain and LangSmith fit into this landscape.\\n\\n**Additional Tips:**\\n\\n1. **Use more technical terms:** While your essay is clear, it's a bit too general. Consider using more technical terms and jargon to make it more informative and valuable for readers.\\n2. **Use examples and anecdotes:** Add more examples and anecdotes to make your essay more engaging and memorable.\\n3. **Use visual aids:** Consider adding diagrams, flowcharts, or other visual aids to help illustrate the concepts and make your essay more engaging.\\n4. **Edit and proofread:** Finally, make sure to edit and proofread your essay carefully to ensure that it's free of errors and flows smoothly.\"}}\n",
      "{'research_critique': {'content': ['In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. | Key Features | Modular chains and sequences, prompt templates, agent framework, data connectors, wide model support, community integrations. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. | Key Features | Modular chains and sequences, prompt templates, agent framework, data connectors, wide model support, community integrations. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', 'In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. | Key Features | Modular chains and sequences, prompt templates, agent framework, data connectors, wide model support, community integrations. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. | Key Features | Modular chains and sequences, prompt templates, agent framework, data connectors, wide model support, community integrations. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', \"LangSmith steps in to give you the tools you need to debug and monitor your models at scale, ensuring everything is running as expected in your AI system. You might think of LangSmith as LangChain's counterpart, but it takes things further by focusing on managing, debugging, and orchestrating AI and ML models. LangSmith steps in to give you the tools you need to debug and monitor your models at scale, ensuring everything is running as expected in your AI system. In short, while LangChain excels at managing and scaling model workflows, LangSmith is designed for when you need deep visibility and control over large, complex AI systems in production. If you're debugging complex AI models or managing large-scale workflows with multiple moving parts, LangSmith's advanced debugging and orchestration features will be indispensable.\", '# AI language models AI language models are a key component of natural language processing (NLP), a field of artificial intelligence (AI) focused on enabling computers to understand and generate human language. This report offers an overview of the AI language model and NLP landscape with current and emerging policy responses from around the world. It explores the basic building blocks of language models from a technical perspective using the OECD Framework for the Classification of AI Systems. The report also presents policy considerations through the lens of the OECD AI Principles. Measuring domestic public cloud compute availability for artificial intelligence Initial policy considerations for generative artificial intelligence G7 Hiroshima Process on Generative Artificial Intelligence (AI) Measuring the environmental impacts of artificial intelligence compute and applications', 'Large language models (LLMs) are machine learning models that can comprehend and generate human language text. A large language model (LLM) is a type of artificial intelligence (AI) program that can recognize and generate text, among other tasks. LLMs are trained on huge sets of data — hence the name \"large.\" LLMs are built on machine learning: specifically, a type of neural network called a transformer model. But the quality of the samples impacts how well LLMs will learn natural language, so an LLM\\'s programmers may use a more curated data set, at least at first. LLMs use a type of machine learning called deep learning in order to understand how characters, words, and sentences function together.', 'LangChain is an open-source framework that gives developers the tools they need to create applications using large language models (LLMs). Furthermore, LangChain’s model management tools let developers work with many language model types and versions, making updates and changes simple. In LangChain, agents are interfaces that combine language models with outside tools and services to create dynamic and interactive applications. Because of LangChain’s modular architecture, developers may easily swap out language models, data sources, and processing stages without compromising the functionality of the entire program. Adopting LangChain in your Artificial Intelligence and Machine Learning projects offers a multitude of advantages, empowering developers and organizations to unlock the full potential of large language models. LangChain empowers developers to create sophisticated conversational AI systems and context-aware applications.', 'LangChain is a modular framework designed to build applications powered by large language models (LLMs). Its architecture allows developers', 'LangSmith integrates with the open-source openevals package to provide a suite of prebuilt evaluators that you can use as starting points for evaluation. This', '... LangSmith Agent Builder is built on our deepagents package with planning capabilities, persistent memory, and multi-step task handling. Its', \"While LangChain helps you build workflows, LangSmith helps ensure that they run smoothly by offering tools for debugging, monitoring and managing complex AI systems. LangSmith provides rich visualization tools to display LLM call traces, helping developers understand and debug complex workflows easily. LangSmith works through a simple Python SDK that helps developers build and manage AI applications easily. Factory, a company building AI agents to automate the Software Development Lifecycle (SDLC), uses LangSmith to help ensure secure, reliable LLM operations in enterprise environments. LangChain is well suited for designing and prototyping complex language model workflows, enabling seamless integration with external tools and APIs. Use LangSmith when you're ready to move into production and need robust tools for debugging, testing, monitoring and maintaining LLM applications at scale.\", 'LangChain is a coding framework for creating LLM-powered apps, LangFlow provides a no-code visual builder on top of LangChain, and LangSmith offers monitoring and evaluation for LLM apps in production. Created in early 2023, LangChain provides a suite of abstractions and tools to help developers chain together LLM calls, manage conversational context, integrate external data sources, and build complex AI agents. | **LangChain** | Coding framework for LLM apps | Chains, prompts, agents, memory, integrations | Core development of AI app logic; full control in production | * **LangChain** provides the powerful, code-based framework needed to build and maintain complex AI applications, with support for chaining, agents, and integrations that form the backbone of many production systems.', 'AI language technology for the future of [large language models](https://www.maxiomtech.com/large-language-model-architecture/) is pivotal today not only because it enhances user interaction across various platforms but also because it drives efficiency and innovation in sectors from healthcare to customer service. The horizon of [AI language technology](https://www.maxiomtech.com/building-a-chatbot-with-large-language-models/) glimmers with breakthroughs, promising more adaptive, context-aware models that refine interactions with a nuanced understanding of dialogues, ensuring more intuitive and human-like exchanges. [Maxiom Tech](https://www.maxiomtech.com/) plays a crucial role in advancing AI language technology, leveraging its robust software development expertise. [Maxiom Tech](https://www.maxiomtech.com/)nology is ambitiously planning to expand its footprint in the AI space with the future of large language models with projects that push the boundaries of AI language technology. [![Image 16: Maxiom Technology - Top Rated Software Development Company in Washington DC](https://www.maxiomtech.com/wp-content/uploads/2015/03/maxiom-positive-nologo-sm.png)](https://www.maxiomtech.com/future-of-large-language-models/#)', 'Explore the shift towards smaller, efficient Large Language Models (LLMs) with reduced energy consumption for a sustainable AI future.']}}\n",
      "{'generate': {'draft': \"Here's a draft essay based on your outline:\\n\\n**The Differences between LangChain and LangSmith: A Comparative Analysis**\\n\\nThe rise of artificial intelligence (AI) has led to the development of various tools and frameworks that enable users to build custom AI applications. Two prominent tools in this space are LangChain and LangSmith, both of which have gained significant attention in recent years. While both tools are AI-powered language tools, they differ in their approach, functionality, and use cases. In this essay, we will explore the differences between LangChain and LangSmith, highlighting their strengths, weaknesses, and applications.\\n\\n**Overview of LangChain**\\n\\nLangChain is an open-source framework that enables users to build custom AI applications using a modular architecture. This framework allows users to create custom AI models and integrate them with various data sources, making it a highly flexible and scalable tool. LangChain's modular architecture enables users to build complex AI applications by chaining together multiple components, each with its own specific function. This flexibility makes LangChain an ideal tool for custom AI development, particularly in industries such as finance, healthcare, and education.\\n\\n**Overview of LangSmith**\\n\\nLangSmith, in contrast, is a commercial AI tool that uses a combination of natural language processing (NLP) and machine learning to generate human-like text. LangSmith's pre-built features make it easier to use for non-technical users, who can simply input text and receive a generated response. LangSmith's strengths lie in its ability to generate coherent and engaging text, making it an ideal tool for content creation and marketing. LangSmith's commercial model also provides users with access to a range of features, including text summarization, translation, and more.\\n\\n**Key differences between LangChain and LangSmith**\\n\\nOne of the primary differences between LangChain and LangSmith is their architecture. LangChain's modular architecture allows for greater flexibility and customization, while LangSmith's pre-built features make it easier to use for non-technical users. This difference in architecture has significant implications for the use cases of each tool. LangChain is best suited for custom AI development, where users require a high degree of flexibility and control. LangSmith, in contrast, is ideal for content creation and marketing, where users require a high-quality, human-like text.\\n\\nAnother key difference between LangChain and LangSmith is their pricing model. LangChain is an open-source framework, which means that users can use it for free. LangSmith, in contrast, is a commercial tool that requires a subscription or one-time payment. This difference in pricing has significant implications for users who are on a budget or who require a high degree of customization.\\n\\n**Conclusion**\\n\\nIn conclusion, LangChain and LangSmith are two distinct tools that cater to different needs and use cases. LangChain's modular architecture and open-source model make it an ideal tool for custom AI development, while LangSmith's pre-built features and commercial model make it ideal for content creation and marketing. As AI technology continues to evolve, it's essential to understand the strengths and weaknesses of different tools like LangChain and LangSmith to make informed decisions about their use in various applications.\\n\\nPlease let me know if you would like me to revise anything or if you have any specific feedback.\", 'revision_number': 3}}\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for s in graph.stream({\n",
    "    'task': \"what is the difference between langchain and langsmith\",\n",
    "    'plan': '',\n",
    "    'draft': '',\n",
    "    'critique': '',\n",
    "    'content': '',\n",
    "    \"max_revisions\": 2,\n",
    "    \"revision_number\": 1,\n",
    "}, thread):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0ad8a6cc-65d4-4ce7-87aa-4e67d7c23d7b",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a draft essay based on your outline:\n",
      "\n",
      "**The Differences between LangChain and LangSmith: A Comparative Analysis**\n",
      "\n",
      "The rise of artificial intelligence (AI) has led to the development of various tools and frameworks that enable users to build custom AI applications. Two prominent tools in this space are LangChain and LangSmith, both of which have gained significant attention in recent years. While both tools are AI-powered language tools, they differ in their approach, functionality, and use cases. In this essay, we will explore the differences between LangChain and LangSmith, highlighting their strengths, weaknesses, and applications.\n",
      "\n",
      "**Overview of LangChain**\n",
      "\n",
      "LangChain is an open-source framework that enables users to build custom AI applications using a modular architecture. This framework allows users to create custom AI models and integrate them with various data sources, making it a highly flexible and scalable tool. LangChain's modular architecture enables users to build complex AI applications by chaining together multiple components, each with its own specific function. This flexibility makes LangChain an ideal tool for custom AI development, particularly in industries such as finance, healthcare, and education.\n",
      "\n",
      "**Overview of LangSmith**\n",
      "\n",
      "LangSmith, in contrast, is a commercial AI tool that uses a combination of natural language processing (NLP) and machine learning to generate human-like text. LangSmith's pre-built features make it easier to use for non-technical users, who can simply input text and receive a generated response. LangSmith's strengths lie in its ability to generate coherent and engaging text, making it an ideal tool for content creation and marketing. LangSmith's commercial model also provides users with access to a range of features, including text summarization, translation, and more.\n",
      "\n",
      "**Key differences between LangChain and LangSmith**\n",
      "\n",
      "One of the primary differences between LangChain and LangSmith is their architecture. LangChain's modular architecture allows for greater flexibility and customization, while LangSmith's pre-built features make it easier to use for non-technical users. This difference in architecture has significant implications for the use cases of each tool. LangChain is best suited for custom AI development, where users require a high degree of flexibility and control. LangSmith, in contrast, is ideal for content creation and marketing, where users require a high-quality, human-like text.\n",
      "\n",
      "Another key difference between LangChain and LangSmith is their pricing model. LangChain is an open-source framework, which means that users can use it for free. LangSmith, in contrast, is a commercial tool that requires a subscription or one-time payment. This difference in pricing has significant implications for users who are on a budget or who require a high degree of customization.\n",
      "\n",
      "**Conclusion**\n",
      "\n",
      "In conclusion, LangChain and LangSmith are two distinct tools that cater to different needs and use cases. LangChain's modular architecture and open-source model make it an ideal tool for custom AI development, while LangSmith's pre-built features and commercial model make it ideal for content creation and marketing. As AI technology continues to evolve, it's essential to understand the strengths and weaknesses of different tools like LangChain and LangSmith to make informed decisions about their use in various applications.\n",
      "\n",
      "Please let me know if you would like me to revise anything or if you have any specific feedback.\n"
     ]
    }
   ],
   "source": [
    "print(s['generate']['draft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b5e62-a203-433c-92a0-3783f490cde1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa923c-7e4f-42d1-965f-0f8ccd50fbd7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c6245-2837-4ac5-983b-95f61f3ac10d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b910915-b087-4d35-afff-0ec30a5852f1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4feb6cc-5129-4a99-bb45-851bc07b5709",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a02b4-96cc-4b01-8792-397a774eb499",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8b86a6-5e20-4252-b1d8-009b8318345a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af925917-b746-48c9-ac74-62fefbe5246c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5048f2c-4d82-49a5-9cb1-918d78b39f7b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f7f1f-68b4-4462-bfa5-b6472ef1304a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac0aa9-baa7-4b58-889d-2118cc00c6b5",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6098b9-e2a9-4767-8cb5-346db835c8d2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d23cf2a-a179-44dc-9ae3-2eddda4b67b4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6005b-0221-4f5e-9be0-0580c1d03126",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1ec12-f1c8-41ae-bb3e-5f28997b9b99",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c07d7-be17-4c17-82c5-6fe1db028b8b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04592c8e-1cfe-4b26-93b5-caf1ed1e7d24",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181c4a9-0e71-4f67-b71f-18a225e37202",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c478a9-7bfe-49e2-8a7d-1536271f45a6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d6771-3fad-4f37-9b32-45b36ad85c59",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3629eb3-655d-467a-b413-63f547c2de08",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f772f251-2b61-4d10-97c5-61cef9207a76",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de92979-7ac5-4a7c-91c1-10806b7d529c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479c4325-f625-4bbf-9d74-cc58f10763f2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4070be7-72da-42f9-a25d-8a6c628788b8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289efbe-7033-4f32-8482-2039c5f9db90",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e480bb-22ab-4acb-a42c-71da3d04a5b1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dea35c-7483-4b3d-b5e3-76eb3a0fe536",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac5730-a9d5-4ea4-8546-ebcb265cf1da",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e1f28b-46d8-4bcd-b2e4-730376ee7ccf",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ac7020-b4f4-4bd2-a875-ccee93f83d83",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f79eb9-d1c9-44b0-9efd-a8f9b380332a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce509206-bde1-43e4-a88f-8a565539d357",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba1590-9e7b-4c0f-9492-81a07d286c55",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8fe4a8-5372-479d-b248-af7a295c86c1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7514720a-14bc-4552-ade5-fa03f86f4c73",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IBM_course_AgenticAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
